{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Agent-on-the-Fly/Memento.git\n%cd Memento/demo\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers\n!pip install --upgrade accelerate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers accelerate vllm openai","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade transformers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade accelerate safetensors sentencepiece\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#voice chat inference\nfrom io import BytesIO\nfrom urllib.request import urlopen\nimport librosa\nfrom transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\nmodel = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\")\n\nconversation = [\n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/guess_age_gender.wav\"},\n    ]},\n    {\"role\": \"assistant\", \"content\": \"Yes, the speaker is female and in her twenties.\"},\n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/translate_to_chinese.wav\"},\n    ]},\n]\ntext = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\naudios = []\nfor message in conversation:\n    if isinstance(message[\"content\"], list):\n        for ele in message[\"content\"]:\n            if ele[\"type\"] == \"audio\":\n                audios.append(librosa.load(\n                    BytesIO(urlopen(ele['audio_url']).read()), \n                    sr=processor.feature_extractor.sampling_rate)[0]\n                )\n\ninputs = processor(text=text, audios=audios, return_tensors=\"pt\", padding=True)\ninputs.input_ids = inputs.input_ids.to(\"cuda\")\n\ngenerate_ids = model.generate(**inputs, max_length=256)\ngenerate_ids = generate_ids[:, inputs.input_ids.size(1):]\n\nresponse = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#audio analysis inference\nfrom io import BytesIO\nfrom urllib.request import urlopen\nimport librosa\nfrom transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\nmodel = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\")\n\nconversation = [\n    {'role': 'system', 'content': 'You are a helpful assistant.'}, \n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/glass-breaking-151256.mp3\"},\n        {\"type\": \"text\", \"text\": \"What's that sound?\"},\n    ]},\n    {\"role\": \"assistant\", \"content\": \"It is the sound of glass shattering.\"},\n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"text\", \"text\": \"What can you do when you hear that?\"},\n    ]},\n    {\"role\": \"assistant\", \"content\": \"Stay alert and cautious, and check if anyone is hurt or if there is any damage to property.\"},\n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/1272-128104-0000.flac\"},\n        {\"type\": \"text\", \"text\": \"What does the person say?\"},\n    ]},\n]\ntext = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\naudios = []\nfor message in conversation:\n    if isinstance(message[\"content\"], list):\n        for ele in message[\"content\"]:\n            if ele[\"type\"] == \"audio\":\n                audios.append(\n                    librosa.load(\n                        BytesIO(urlopen(ele['audio_url']).read()), \n                        sr=processor.feature_extractor.sampling_rate)[0]\n                )\n\ninputs = processor(text=text, audios=audios, return_tensors=\"pt\", padding=True)\ninputs.input_ids = inputs.input_ids.to(\"cuda\")\n\ngenerate_ids = model.generate(**inputs, max_length=256)\ngenerate_ids = generate_ids[:, inputs.input_ids.size(1):]\n\nresponse = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Batch Inference\nfrom io import BytesIO\nfrom urllib.request import urlopen\nimport librosa\nfrom transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\nmodel = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\")\n\nconversation1 = [\n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/glass-breaking-151256.mp3\"},\n        {\"type\": \"text\", \"text\": \"What's that sound?\"},\n    ]},\n    {\"role\": \"assistant\", \"content\": \"It is the sound of glass shattering.\"},\n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/f2641_0_throatclearing.wav\"},\n        {\"type\": \"text\", \"text\": \"What can you hear?\"},\n    ]}\n]\n\nconversation2 = [\n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/1272-128104-0000.flac\"},\n        {\"type\": \"text\", \"text\": \"What does the person say?\"},\n    ]},\n]\n\nconversations = [conversation1, conversation2]\n\ntext = [processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False) for conversation in conversations]\n\naudios = []\nfor conversation in conversations:\n    for message in conversation:\n        if isinstance(message[\"content\"], list):\n            for ele in message[\"content\"]:\n                if ele[\"type\"] == \"audio\":\n                    audios.append(\n                        librosa.load(\n                            BytesIO(urlopen(ele['audio_url']).read()), \n                            sr=processor.feature_extractor.sampling_rate)[0]\n                    )\n\ninputs = processor(text=text, audios=audios, return_tensors=\"pt\", padding=True)\ninputs['input_ids'] = inputs['input_ids'].to(\"cuda\")\ninputs.input_ids = inputs.input_ids.to(\"cuda\")\n\ngenerate_ids = model.generate(**inputs, max_length=256)\ngenerate_ids = generate_ids[:, inputs.input_ids.size(1):]\n\nresponse = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pre-trained base model\nfrom io import BytesIO\nfrom urllib.request import urlopen\nimport librosa\nfrom transformers import AutoProcessor, Qwen2AudioForConditionalGeneration\n\nmodel = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B\" ,trust_remote_code=True)\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B\" ,trust_remote_code=True)\n\nprompt = \"<|audio_bos|><|AUDIO|><|audio_eos|>Generate the caption in English:\"\nurl = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Audio/glass-breaking-151256.mp3\"\naudio, sr = librosa.load(BytesIO(urlopen(url).read()), sr=processor.feature_extractor.sampling_rate)\ninputs = processor(text=prompt, audios=audio, return_tensors=\"pt\")\n\ngenerated_ids = model.generate(**inputs, max_length=256)\ngenerated_ids = generated_ids[:, inputs.input_ids.size(1):]\nresponse = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}